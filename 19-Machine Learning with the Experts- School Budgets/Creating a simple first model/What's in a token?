# Instructions:

- Import CountVectorizer from sklearn.feature_extraction.text.
- Instantiate vec_basic and vec_alphanumeric using, respectively, the TOKENS_BASIC and TOKENS_ALPHANUMERIC patterns.
- Create the text vector by using the combine_text_columns() function on df.
- Using the .fit_transform() method with text_vector, 
   fit and transform first vec_basic and then vec_alphanumeric. Print the number of tokens they contain.
   
# Solutions:

      # Import the CountVectorizer
      from sklearn.feature_extraction.text import CountVectorizer

      # Create the basic token pattern
      TOKENS_BASIC = '\\S+(?=\\s+)'

      # Create the alphanumeric token pattern
      TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\s+)'

      # Instantiate basic CountVectorizer: vec_basic
      vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)

      # Instantiate alphanumeric CountVectorizer: vec_alphanumeric
      vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)

      # Create the text vector
      text_vector = combine_text_columns(df)

      # Fit and transform vec_basic
      vec_basic.fit_transform(text_vector)

      # Print number of tokens of vec_basic
      print("There are {} tokens in the dataset".format(len(vec_basic.get_feature_names())))

      # Fit and transform vec_alphanumeric
      vec_alphanumeric.fit_transform(text_vector)

      # Print number of tokens of vec_alphanumeric
      print("There are {} alpha-numeric tokens in the dataset".format(len(vec_alphanumeric.get_feature_names())))
